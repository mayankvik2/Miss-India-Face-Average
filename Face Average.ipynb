{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImagePaths(path):\n",
    "  # Create array of array of images.\n",
    "  imagePaths = []\n",
    "  # List all files in the directory and read points from text files one by one\n",
    "  for filePath in sorted(os.listdir(path)):\n",
    "    fileExt = os.path.splitext(filePath)[1]\n",
    "    if fileExt in [\".jpg\", \".jpeg\"]:\n",
    "      print(filePath)\n",
    "\n",
    "      # Add to array of images\n",
    "      imagePaths.append(os.path.join(path, filePath))\n",
    "\n",
    "  return imagePaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns 8 points on the boundary of a rectangle\n",
    "def getEightBoundaryPoints(h, w):\n",
    "  boundaryPts = []\n",
    "  boundaryPts.append((0,0))\n",
    "  boundaryPts.append((w/2, 0))\n",
    "  boundaryPts.append((w-1,0))\n",
    "  boundaryPts.append((w-1, h/2))\n",
    "  boundaryPts.append((w-1, h-1))\n",
    "  boundaryPts.append((w/2, h-1))\n",
    "  boundaryPts.append((0, h-1))\n",
    "  boundaryPts.append((0, h/2))\n",
    "  return np.array(boundaryPts, dtype=np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImagesAndLandmarks(outSize, imIn, pointsIn):\n",
    "  h, w = outSize\n",
    "  # Corners of the eye in input image\n",
    "  eyecornerSrc = [pointsIn[36], pointsIn[45]]\n",
    "\n",
    "  # Corners of the eye in normalized image\n",
    "  eyecornerDst = [(np.int(0.3 * w), np.int(h/3)), \n",
    "                  (np.int(0.7 * w), np.int(h/3))]\n",
    "\n",
    "  # Calculate similarity transform\n",
    "  tform = similarityTransform(eyecornerSrc, eyecornerDst)\n",
    "  imOut = np.zeros(imIn.shape, dtype=imIn.dtype)\n",
    "  # Apply similarity transform to input image\n",
    "  imOut = cv2.warpAffine(imIn, tform, (w, h))\n",
    "  # reshape pointsIn from numLandmarks x 2 to numLandmarks x 1 x 2\n",
    "  points2 = np.reshape(pointsIn, (pointsIn.shape[0], 1, pointsIn.shape[1]))\n",
    "    \n",
    "  pointsOut = cv2.transform(points2, tform)\n",
    "  pointsOut = np.reshape(pointsOut, (pointsIn.shape[0], pointsIn.shape[1]))\n",
    "\n",
    "  return imOut, pointsOut\n",
    "\n",
    "def similarityTransform(inPoints, outPoints):\n",
    "  s60 = math.sin(60*math.pi/180)\n",
    "  c60 = math.cos(60*math.pi/180)\n",
    "\n",
    "  inPts = np.copy(inPoints).tolist()\n",
    "  outPts = np.copy(outPoints).tolist()\n",
    "\n",
    "  # The third point is calculated so that the three points make an equilateral triangle\n",
    "  xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0]\n",
    "  yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1]\n",
    "\n",
    "  inPts.append([np.int(xin), np.int(yin)])\n",
    "\n",
    "  xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0]\n",
    "  yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1]\n",
    "\n",
    "  outPts.append([np.int(xout), np.int(yout)])\n",
    "\n",
    "  # estimateRigidTransform for calculating the similarity transform.\n",
    "  tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False)\n",
    "  return tform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Dlib shape detector object to list of tuples\n",
    "def dlibLandmarksToPoints(shape):\n",
    "  points = []\n",
    "  for p in shape.parts():\n",
    "    pt = (p.x, p.y)\n",
    "    points.append(pt)\n",
    "  return points\n",
    "\n",
    "# Dlib Landmark Detector\n",
    "def getLandmarks(faceDetector, landmarkDetector, im, FACE_DOWNSAMPLE_RATIO = 1):\n",
    "  points = []\n",
    "  imSmall = cv2.resize(im,None,\n",
    "                       fx=1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                       fy=1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                       interpolation = cv2.INTER_LINEAR)\n",
    "  \n",
    "  faceRects = faceDetector(imSmall, 0)\n",
    "  \n",
    "  if len(faceRects) > 0:\n",
    "    maxArea = 0\n",
    "    maxRect = None\n",
    "    # TODO: test on images with multiple faces\n",
    "    for face in faceRects:\n",
    "      if face.area() > maxArea:\n",
    "        maxArea = face.area()\n",
    "        maxRect = [face.left(),\n",
    "                   face.top(),\n",
    "                   face.right(),\n",
    "                   face.bottom()\n",
    "                  ]\n",
    "    \n",
    "    rect = dlib.rectangle(*maxRect)\n",
    "    scaledRect = dlib.rectangle(int(rect.left()*FACE_DOWNSAMPLE_RATIO),\n",
    "                             int(rect.top()*FACE_DOWNSAMPLE_RATIO),\n",
    "                             int(rect.right()*FACE_DOWNSAMPLE_RATIO),\n",
    "                             int(rect.bottom()*FACE_DOWNSAMPLE_RATIO))\n",
    "    \n",
    "    landmarks = landmarkDetector(im, scaledRect)\n",
    "    points = dlibLandmarksToPoints(landmarks)\n",
    "  return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a point is inside a rectangle\n",
    "def rectContains(rect, point):\n",
    "  if point[0] < rect[0]:\n",
    "    return False\n",
    "  elif point[1] < rect[1]:\n",
    "    return False\n",
    "  elif point[0] > rect[2]:\n",
    "    return False\n",
    "  elif point[1] > rect[3]:\n",
    "    return False\n",
    "  return True\n",
    "\n",
    "# Calculate Delaunay triangles for set of points\n",
    "\n",
    "def calculateDelaunayTriangles(rect, points):\n",
    "  subdiv = cv2.Subdiv2D(rect)\n",
    "  for p in points:\n",
    "    subdiv.insert((p[0], p[1]))\n",
    "  # Get Delaunay triangulation\n",
    "  triangleList = subdiv.getTriangleList()\n",
    "  delaunayTri = []\n",
    "  for t in triangleList:\n",
    "    # The triangle returned by getTriangleList \n",
    "    pt = []\n",
    "    pt.append((t[0], t[1]))\n",
    "    pt.append((t[2], t[3]))\n",
    "    pt.append((t[4], t[5]))\n",
    "\n",
    "    pt1 = (t[0], t[1])\n",
    "    pt2 = (t[2], t[3])\n",
    "    pt3 = (t[4], t[5])\n",
    "\n",
    "    if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
    "      ind = []\n",
    "      # Find the index of each vertex in the points list\n",
    "      for j in range(0, 3):\n",
    "        for k in range(0, len(points)):\n",
    "          if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
    "            ind.append(k)\n",
    "        # Store triangulation as a list of indices\n",
    "      if len(ind) == 3:\n",
    "        delaunayTri.append((ind[0], ind[1], ind[2]))\n",
    "\n",
    "  return delaunayTri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply affine transform \n",
    "def applyAffineTransform(src, srcTri, dstTri, size):\n",
    "\n",
    "  # Given a pair of triangles, find the affine transform.\n",
    "  warpMat = cv2.getAffineTransform(np.float32(srcTri), np.float32(dstTri))\n",
    "\n",
    "  # Apply the Affine Transform just found to the src image\n",
    "  dst = cv2.warpAffine(src, warpMat, (size[0], size[1]), None,\n",
    "             flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "  return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrains points to be inside boundary\n",
    "def constrainPoint(p, w, h):\n",
    "  p = (min(max(p[0], 0), w - 1), min(max(p[1], 0), h - 1))\n",
    "  return p\n",
    "\n",
    "def warpImage(imIn, pointsIn, pointsOut, delaunayTri):\n",
    "  h, w, ch = imIn.shape\n",
    "  # Output image\n",
    "  imOut = np.zeros(imIn.shape, dtype=imIn.dtype)\n",
    "  for j in range(0, len(delaunayTri)):\n",
    "    tin = []\n",
    "    tout = []\n",
    "\n",
    "    for k in range(0, 3):\n",
    "      # Extract a vertex of input triangle\n",
    "      pIn = pointsIn[delaunayTri[j][k]]\n",
    "      pIn = constrainPoint(pIn, w, h)\n",
    "      pOut = pointsOut[delaunayTri[j][k]]\n",
    "      pOut = constrainPoint(pOut, w, h)\n",
    "      tin.append(pIn)\n",
    "      tout.append(pOut)\n",
    "\n",
    "    # Warp pixels inside input triangle to output triangle.\n",
    "    warpTriangle(imIn, imOut, tin, tout)\n",
    "  return imOut\n",
    "\n",
    "def warpTriangle(img1, img2, t1, t2):\n",
    "  # Find bounding rectangle for each triangle\n",
    "  r1 = cv2.boundingRect(np.float32([t1]))\n",
    "  r2 = cv2.boundingRect(np.float32([t2]))\n",
    "  t1Rect = []\n",
    "  t2Rect = []\n",
    "  t2RectInt = []\n",
    "\n",
    "  for i in range(0, 3):\n",
    "    t1Rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
    "    t2Rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "    t2RectInt.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "\n",
    "  # Get mask by filling triangle\n",
    "  mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)\n",
    "  cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0)\n",
    "  img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "  size = (r2[2], r2[3])\n",
    "  img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
    "  img2Rect = img2Rect * mask\n",
    "   # Copy triangular region of the rectangular patch to the output image\n",
    "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ((1.0, 1.0, 1.0) - mask)\n",
    "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_4970-600x900.jpg\n",
      "Miss India Grand Finale.jpg\n",
      "Shreya Kamavarapu Photos_12.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "  # Landmark model location\n",
    "  PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "  faceDetector = dlib.get_frontal_face_detector()\n",
    "  # The landmark detector is implemented in the shape_predictor class\n",
    "  landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "  dirName = \"C:/Users/Mayank Vikram/Documents/Computer Vision/week4/practice/Miss India\"\n",
    "  # Read all images\n",
    "  imagePaths = readImagePaths(dirName) \n",
    "  if len(imagePaths) == 0:\n",
    "    print('No images found with extension jpg or jpeg')\n",
    "    sys.exit(0)\n",
    "\n",
    "  # Read images and perform landmark detection.\n",
    "  images = []\n",
    "  allPoints = []\n",
    "  for imagePath in imagePaths:\n",
    "    im = cv2.imread(imagePath)\n",
    "    if im is None:\n",
    "      print(\"image:{} not read properly\".format(imagePath))\n",
    "    else:\n",
    "        points = getLandmarks(faceDetector, landmarkDetector, im)\n",
    "        if len(points) > 0:\n",
    "          allPoints.append(points)\n",
    "\n",
    "          im = np.float32(im)/255.0\n",
    "          images.append(im)\n",
    "        else:\n",
    "          print(\"Couldn't detect face landmarks\")\n",
    "\n",
    "\n",
    "  if len(images) == 0:\n",
    "    print(\"No images found\")\n",
    "    sys.exit(0)\n",
    "  # Dimensions of output image\n",
    "  w = 600\n",
    "  h = 600\n",
    "\n",
    "  # 8 Boundary points for Delaunay Triangulation\n",
    "  boundaryPts = getEightBoundaryPoints(h, w)\n",
    "\n",
    "  numImages = len(imagePaths)\n",
    "  numLandmarks = len(allPoints[0])\n",
    "\n",
    "  # Variables to store normalized images and points.\n",
    "  imagesNorm = []\n",
    "  pointsNorm = []\n",
    "  # Initialize location of average points to 0s\n",
    "  pointsAvg = np.zeros((numLandmarks, 2), dtype=np.float32)\n",
    "\n",
    "  # Warp images and trasnform landmarks to output coordinate system,\n",
    "  # and find average of transformed landmarks.\n",
    "  for i, img in enumerate(images):\n",
    "\n",
    "    points = allPoints[i]\n",
    "    points = np.array(points)\n",
    "\n",
    "    img, points = normalizeImagesAndLandmarks((h, w), img, points)\n",
    "\n",
    "    # Calculate average landmark locations\n",
    "    pointsAvg = pointsAvg + (points / (1.0*numImages))\n",
    "\n",
    "    # Append boundary points. Will be used in Delaunay Triangulation\n",
    "    points = np.concatenate((points, boundaryPts), axis=0)\n",
    "\n",
    "    pointsNorm.append(points)\n",
    "    imagesNorm.append(img)\n",
    "   # Append boundary points to average points.\n",
    "  pointsAvg = np.concatenate((pointsAvg, boundaryPts), axis=0)\n",
    "\n",
    "  # Delaunay triangulation\n",
    "  rect = (0, 0, w, h)\n",
    "  dt = calculateDelaunayTriangles(rect, pointsAvg)\n",
    "\n",
    "  # Output image\n",
    "  output = np.zeros((h, w, 3), dtype=np.float)\n",
    "\n",
    "  # Warp input images to average image landmarks\n",
    "  for i in range(0, numImages):\n",
    "\n",
    "    imWarp = warpImage(imagesNorm[i], pointsNorm[i], pointsAvg.tolist(), dt)\n",
    "\n",
    "    # Add image intensities for averaging\n",
    "    output = output + imWarp\n",
    "\n",
    "  # Divide by numImages to get average\n",
    "  output = output / (1.0*numImages)\n",
    "  cv2.imwrite(\"finalpic1.jpg\",output) \n",
    "  # Display result\n",
    "  cv2.imshow('image', output)\n",
    "  cv2.waitKey(0)  \n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
